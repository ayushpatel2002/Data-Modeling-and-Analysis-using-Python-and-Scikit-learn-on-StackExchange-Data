{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Classification on Unseen Data (total 8 points)\n",
    "In this final task, you should read the feather file 'TestQuestionsDF.feather.zstd' into a pandas dataframe. Hereafter this will be referred to as the test_set. <br>You can assume that the test_set is a random sample from the same dataset as 'TrainQuestionsDF.feather.zstd' (hereafter train_set).\n",
    "Your goal is to classify the data in the test_set and achieve the best **average f1-score** using the train_set.\n",
    "You are allowed to utilize any technique and model available in the scikit-learn library or the standard python libraries to do so.\n",
    "Pay particular attention to the lessons learned from your experiments in the Classification notebook -- any of these approaches can be used to construct the model you use for prediction.\n",
    "You can additionally choose to generate and/or construct any features from the available data. Remember that the test_set should be represented with the same feature space as the train_set. <br>For example, features based on text should be constructed with the same vocabulary on the test_set as the train_set.<br>\n",
    "To achieve a high f1 score on unseen data, remember to utilize all the techniques you've learned in the lectures, lectorials and practicals.\n",
    "\n",
    "For this task, you are expected to submit the following:\n",
    "1. This notebook with your code, the code should be well documented and must run without errors.\n",
    "    There is no time limit, but it is a good practice to save the parameters of the best model and add an option to generate a model with those parameters. Without running the full tuning of the hyper-parameters. <br>\n",
    "2. Up to 4 prediction files, each predictions file will have exactly two columns: \"Id\" and \"Label\" with these headers and no other columns (e.g. index).<br>\n",
    " The file names should be SXXXXXXX-A2-predictions-\\<n\\>.csv - where n is a running integer {1,2,3,4}.\n",
    "\n",
    "Your mark in this task will depend on the following:\n",
    "1. The code is well documented, and the entire notebook runs without errors (1 points).\n",
    "2. The submitted solutions are reproducible, i.e. the submitted code can generate the submitted prediction files (2 points).\n",
    "3. The highest (out of the 4 prediction files) achieved average f1-score is in the following range:\n",
    " * (0.8, 1] (5 points)\n",
    " * (0.7, 0.8] (4 points)\n",
    " * (0.65, 0.7] (3 points)\n",
    " * (0, 0.65] (1 point)\n",
    "\n",
    "To support the reproducibility of your solution, use the random seed anywhere where the solution involves a random process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Any additional (if needed) import statements should be in this cell\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.sparse\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Set the random seed as your student id (only numbers)\n",
    "RANDOM_SEED = 3891013\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_feather_to_df(feather_file_name):\n",
    "    \"\"\"\n",
    "    The function expects to receive a path to feather file,\n",
    "    it will read the file from the disk into a pandas dataframe\n",
    "    \"\"\"\n",
    "    return pd.read_feather(feather_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Converted test and training files from feather to dataframes\n",
    "train_df = read_feather_to_df('TrainQuestionsDF.feather.zstd')\n",
    "test_df = read_feather_to_df('TestQuestionsDF.feather.zstd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Write your code below.\n",
    "# You can split it into as many cells and functions as you see fit to make it readable and well documented.\n",
    "\n",
    "def series_to_tfidf(sr, **tfidfvectorizer_kwargs):\n",
    "    \"\"\"\n",
    "    The function receives an array or a pandas Series that contains text strings (a.k.a documents).\n",
    "    It then converts the documents into a matrix of TF-IDF features\n",
    "    The function should return two objects:\n",
    "    TfidfVectorizer object after it learned (fitted) the vocabulary and idf from the training set,\n",
    "    and a document-term matrix (the original documents array transformed into a TF-IDF features matrix).\n",
    "    :param sr: pd.Series, contains text strings\n",
    "    :param tfidfvectorizer_kwargs: key-word arguments that will be passed to TfidfVectorizer class\n",
    "    :return: two objects, the fitted TfidfVectorizer object and the tf-idf document-term sparse matrix\n",
    "    \"\"\"\n",
    "    # TODO: write your code here\n",
    "    vectorizer = TfidfVectorizer(analyzer = 'word', token_pattern=r\"(?u)\\b\\w[\\w-]*\\w\\b|\\b\\w+\\b\", stop_words='english')\n",
    "    TfidfVectorizer_object = vectorizer.fit(sr)\n",
    "    sparse_matrix = vectorizer.fit_transform(sr)\n",
    "    return TfidfVectorizer_object, sparse_matrix\n",
    "\n",
    "\n",
    "def linear_svc(X, y, **linearsvc_kwargs):\n",
    "#     :param training dataframe and corresponding array or series of labels\n",
    "#     Called the LinearSVC model and named it as svc\n",
    "    svc = LinearSVC()\n",
    "#     Fitted the models with with training set and labels\n",
    "    fit = svc.fit(X, y)\n",
    "#     densified the model\n",
    "    dense = fit.densify()\n",
    "#     returning the fitted LinearSVC model\n",
    "    return fit\n",
    "\n",
    "def random_forest(X, y, **random_forest_kwargs):\n",
    "#     :param training dataframe and corresponding array or series of labels\n",
    "# Called the Random Forest model and named it as random_forest with estimators equal to 200\n",
    "    random_forest = RandomForestClassifier(n_estimators=200)\n",
    "#     Fitted the models with training set and labels\n",
    "    fit = random_forest.fit(X, y)\n",
    "#     returning the fitted Random Forest model\n",
    "    return fit\n",
    "    \n",
    "def create_csv(predictions, filename):\n",
    "     '''The function takes 2 parameters, 'predictions' is array or list of predictions generated by models and 'filename'\n",
    "     is name of file to be saved on the disk. \n",
    "    '''\n",
    "#         array of index would be produced based on the number of predictions in the input array\n",
    "    index = range(len(predictions))\n",
    "#     Creating a dictionary consisting of name of columns or headers(Id and Label) and index array and prediction array as their value\n",
    "    d = {'Id': index, 'Label': predictions}\n",
    "#     converting the dictionary to dataframe\n",
    "    df = pd.DataFrame(data=d)\n",
    "#     writitng dataframe to a CSV file of inteded name\n",
    "    df.to_csv(filename, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliited the data based on 2 columns to carry out text based prediction. The columns are 'Title' and 'Body'\n",
    "# Trained the data with same vocabulary as Title and Body columns of train_df\n",
    "X_train, X_test, y_train, y_test = train_test_split((series_to_tfidf(train_df[\"Title\"])[1]), train_df['Label'], test_size=0.2, random_state=RANDOM_SEED)\n",
    "X_train_body, X_test_body, y_train, y_test = train_test_split((series_to_tfidf(train_df[\"Body\"])[1]), train_df['Label'], test_size=0.2, random_state=RANDOM_SEED)\n",
    "test_set_body = series_to_tfidf(train_df[\"Body\"])[0].transform(test_df[\"Body\"])\n",
    "test_set_title = series_to_tfidf(train_df[\"Title\"])[0].transform(test_df[\"Title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised the data for better result. It is important to bring data to one scale. \n",
    "normalised_train = normalize(X_train)\n",
    "normalised_test = normalize(X_test)\n",
    "normalised_test_body = normalize(X_test_body)\n",
    "normalised_test_set_body = normalize(test_set_body)\n",
    "normalised_test_set_title = normalize(test_set_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions called for fitting and training the models with appropriate training data and named them according to the \n",
    "# data they have trained and fitted with\n",
    "fitted_random_forest_with_title = random_forest(normalize(X_train), y_train)\n",
    "fitted_random_forest_with_body = random_forest(normalize(X_train_body), y_train)\n",
    "fitted_linear_svc = linear_svc((X_train_body), y_train)\n",
    "fitted_linear_svc_with_title = linear_svc((X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 for Random Forest with Column Body:  0.7290954694880798\n"
     ]
    }
   ],
   "source": [
    "# Tested and printed the F1 score of predictions made on test data of train_df by Random Forest algorithm based on 'Body' column\n",
    "pred22 = fitted_random_forest_with_body.predict(normalize(X_test_body))\n",
    "print(\"Average F1 for Random Forest with Column Body: \", f1_score(y_test, pred22, average = \"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 for Random Forest with Column Title:  0.6931656726287834\n"
     ]
    }
   ],
   "source": [
    "# Tested and printed the F1 score of predictions made on test data of train_df by Random Forest algorithm based on 'Title' column\n",
    "pred21 = fitted_random_forest_with_title.predict(normalize(X_test))\n",
    "print(\"Average F1 for Random Forest with Column Title: \", f1_score(y_test, pred21, average = \"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 for Linear SVC with Column Body:  0.7395513207878044\n"
     ]
    }
   ],
   "source": [
    "# Tested and printed the F1 score of predictions made on test data of train_df by LnearSVC algorithm based on 'Body' column\n",
    "pred20 = fitted_linear_svc.predict(X_test_body)\n",
    "print(\"Average F1 for Linear SVC with Column Body: \", f1_score(y_test, pred20, average = \"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 for Linear SVC with Column Title:  0.6866223635754027\n"
     ]
    }
   ],
   "source": [
    "# Tested and printed the F1 score of predictions made on test data of train_df by LnearSVC algorithm based on 'Title' column\n",
    "pred19 = fitted_linear_svc_with_title.predict(X_test)\n",
    "print(\"Average F1 for Linear SVC with Column Title: \", f1_score(y_test, pred19, average = \"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted labels of testing set(unseen data) with trained Random Forest model taking 'Body' as its features for text based prediction\n",
    "pred_with_random_forest1 = fitted_random_forest_with_body.predict(normalize(test_set_body))\n",
    "# Printing the predictions to a CSV file\n",
    "create_csv(pred_with_random_forest1, \"S3891013-A2-predictions-1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted labels of testing set(unseen data) with trained Random Forest model taking 'Title' as its features for text based prediction\n",
    "pred_with_random_forest2 = fitted_random_forest_with_title.predict(normalize(test_set_title))\n",
    "# Printing the predictions to a CSV file\n",
    "create_csv(pred_with_random_forest2, \"S3891013-A2-predictions-2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted labels of testing set(unseen data) with trained LinearSVC model taking 'Body' as its features for text based prediction\n",
    "pred_with_linear_svc1 = fitted_linear_svc.predict(test_set_body)\n",
    "# Printing the predictions to a CSV file\n",
    "create_csv(pred_with_linear_svc1, \"S3891013-A2-predictions-3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted labels of testing set(unseen data) with trained LinearSVC model taking 'Title' as its features for text based prediction\n",
    "pred_with_linear_svc2 = fitted_linear_svc_with_title.predict(test_set_title)\n",
    "# Printing the predictions to a CSV file\n",
    "create_csv(pred_with_linear_svc2, \"S3891013-A2-predictions-4.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
